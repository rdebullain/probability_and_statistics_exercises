{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# package with hypothesis tests\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the data from [**here**](https://drive.google.com/file/d/0Bz9_0VdXvv9bUUNlUTVrMF9VcVU/view?usp=sharing&resourcekey=0-16O9Fc5eaJH99-M7AHqHOg). The data contains results of all NBA games from seasons 2013/2014 to 2015/2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nba_games_13_15.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>...</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>MIN</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>21501226</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>MIN vs. NOP</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "      <td>21501225</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>MIL vs. IND</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>21501217</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>BOS vs. MIA</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>LAL</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>21501228</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>LAL vs. UTA</td>\n",
       "      <td>W</td>\n",
       "      <td>239</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>21501220</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>CLE vs. DET</td>\n",
       "      <td>L</td>\n",
       "      <td>265</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON_ID     TEAM_ID TEAM_ABBREVIATION               TEAM_NAME   GAME_ID  \\\n",
       "0      22015  1610612750               MIN  Minnesota Timberwolves  21501226   \n",
       "1      22015  1610612749               MIL         Milwaukee Bucks  21501225   \n",
       "2      22015  1610612738               BOS          Boston Celtics  21501217   \n",
       "3      22015  1610612747               LAL      Los Angeles Lakers  21501228   \n",
       "4      22015  1610612739               CLE     Cleveland Cavaliers  21501220   \n",
       "\n",
       "    GAME_DATE      MATCHUP WL  MIN  PTS  ...  FT_PCT  OREB  DREB  REB  AST  \\\n",
       "0  2016-04-13  MIN vs. NOP  W  240  144  ...   0.826     5    38   43   41   \n",
       "1  2016-04-13  MIL vs. IND  L  240   92  ...   0.846     7    36   43   23   \n",
       "2  2016-04-13  BOS vs. MIA  W  240   98  ...   0.864    10    29   39   20   \n",
       "3  2016-04-13  LAL vs. UTA  W  239  101  ...   0.867     8    39   47   19   \n",
       "4  2016-04-13  CLE vs. DET  L  265  110  ...   0.733     8    35   43   21   \n",
       "\n",
       "   STL  BLK  TOV  PF  PLUS_MINUS  \n",
       "0   14    8   13  20        35.0  \n",
       "1    8    3   15  15        -5.0  \n",
       "2    7    3    7  20        10.0  \n",
       "3    6    3   13  17         5.0  \n",
       "4    4    7   10  23        -2.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SEASON_ID', 'TEAM_ID', 'TEAM_ABBREVIATION', 'TEAM_NAME', 'GAME_ID',\n",
       "       'GAME_DATE', 'MATCHUP', 'WL', 'MIN', 'PTS', 'FGM', 'FGA', 'FG_PCT',\n",
       "       'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB',\n",
       "       'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PLUS_MINUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Task 1\n",
    "Split the data into **3** separate dataframes for each NBA season!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame based on 'SEASON_ID'\n",
    "df_2013 = df[df['SEASON_ID'] == 22013]\n",
    "df_2014 = df[df['SEASON_ID'] == 22014]\n",
    "df_2015 = df[df['SEASON_ID'] == 22015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "### Task 2\n",
    "Test the hypothesis that the offensive productions stats of the Cleveland Cavaliers and Golden State Warriors (the teams that met in the finals that year) were from the same distribution in the 2015/2016 season.\n",
    "\n",
    "Offensive production refers to two variables: **PTS (Points)** and **FG_PCT (Field Goal Percentage)**. We will need to do two separate hypothesis tests, one for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Null Hypothesis (H0): The offensive production stats (PTS and FG_PCT) of the Cleveland Cavaliers and Golden State Warriors come from the same distribution in the 2015 season.\n",
    "- Alternative Hypothesis (H1): The offensive production stats (PTS and FG_PCT) of the Cleveland Cavaliers and Golden State Warriors do not come from the same distribution in the 2015 season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=1683.500, p=0.000\n",
      "Different distribution (reject H0) for PTS\n",
      "Statistics=2452.500, p=0.003\n",
      "Different distribution (reject H0) for FG_PCT\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Filter data for the two teams\n",
    "cavs = df_2015[df_2015['TEAM_NAME'] == 'Cleveland Cavaliers']\n",
    "warriors = df_2015[df_2015['TEAM_NAME'] == 'Golden State Warriors']\n",
    "\n",
    "# Perform Mann-Whitney U test for 'PTS'\n",
    "stat, p = mannwhitneyu(cavs['PTS'], warriors['PTS'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0) for PTS')\n",
    "else:\n",
    "    print('Different distribution (reject H0) for PTS')\n",
    "\n",
    "# Perform Mann-Whitney U test for 'FG_PCT'\n",
    "stat, p = mannwhitneyu(cavs['FG_PCT'], warriors['FG_PCT'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# Interpretation\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0) for FG_PCT')\n",
    "else:\n",
    "    print('Different distribution (reject H0) for FG_PCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the results:\n",
    "\n",
    "1. For 'PTS' (Points):\n",
    "   - The Mann-Whitney U statistic is 1683.500. This is the sum of the ranks in the two samples.\n",
    "   - The p-value is 0.000, which is less than the alpha level of 0.05. This means rejecting the null hypothesis that the 'PTS' for the Cleveland Cavaliers and Golden State Warriors come from the same distribution in the 2015 season. The data suggests that the 'PTS' for the two teams come from different distributions.\n",
    "\n",
    "2. For 'FG_PCT' (Field Goal Percentage):\n",
    "   - The Mann-Whitney U statistic is 2452.500.\n",
    "   - The p-value is 0.003, which is also less than the alpha level of 0.05. This means rejecting the null hypothesis that the 'FG_PCT' for the Cleveland Cavaliers and Golden State Warriors come from the same distribution in the 2015 season. The data suggests that the 'FG_PCT' for the two teams come from different distributions.\n",
    "\n",
    "In conclusion, both the 'PTS' and 'FG_PCT' offensive production stats for the Cleveland Cavaliers and Golden State Warriors appear to come from different distributions in the 2015 season, according to the data and the Mann-Whitney U test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### Task 3\n",
    "Test the hypothesis that the number of points (PTS) scored by Cleveland Cavaliers changed significantly after the head coach changed in the 2015/2016 season.\n",
    "\n",
    "- **Coach Blatt was fired on 24th of Jan, 2016**. \n",
    "\n",
    "Use the data from seasons 2014/2015 and 2015/2016 - those are years when Cleveland was coached by Blatt. \n",
    "\n",
    "**We have two possible solutions to try here:**\n",
    "- Take the same amount of games from before and after and try t-test.\n",
    "- Take all the games from before and after and look for the right test to compare two samples with different sizes. (You will need to go through the scipy documentation or google to figure out what kind of test is required.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=-2.911, p=0.005\n",
      "Different distribution (reject H0) for PTS\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Filter data for Cleveland Cavaliers\n",
    "cavs = df[(df['TEAM_NAME'] == 'Cleveland Cavaliers') & ((df['SEASON_ID'] == 22014) | (df['SEASON_ID'] == 22015))]\n",
    "\n",
    "# Convert GAME_DATE to datetime\n",
    "cavs.loc[:, 'GAME_DATE'] = pd.to_datetime(cavs['GAME_DATE'])\n",
    "\n",
    "# Define coach change date as Timestamp\n",
    "coach_change_date = pd.to_datetime('2016-01-24')\n",
    "\n",
    "# Split data based on the coach change date\n",
    "before_coach_change = cavs[cavs['GAME_DATE'] < coach_change_date]\n",
    "after_coach_change = cavs[cavs['GAME_DATE'] >= coach_change_date]\n",
    "\n",
    "# Get the same number of games from before and after the coach change\n",
    "min_games = min(len(before_coach_change), len(after_coach_change))\n",
    "before_coach_change = before_coach_change.sort_values('GAME_DATE', ascending=False).head(min_games)\n",
    "after_coach_change = after_coach_change.sort_values('GAME_DATE').head(min_games)\n",
    "\n",
    "# Perform t-test\n",
    "stat, p = ttest_ind(before_coach_change['PTS'], after_coach_change['PTS'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0) for PTS')\n",
    "else:\n",
    "    print('Different distribution (reject H0) for PTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Statistics` value (-2.911) is the test statistic from the t-test. A negative value indicates that the first sample's mean (before the coach change) is less than the second sample's mean (after the coach change).\n",
    "\n",
    "The `p` value (0.005) is the probability of observing a test statistic as extreme as the one obtained (or more extreme) if the null hypothesis (H0) is true. \n",
    "\n",
    "In this case, the null hypothesis (H0) is that the two distributions are the same, or in other words, the mean points scored (PTS) before and after the coach change are the same.\n",
    "\n",
    "Because the p-value is less than the significance level (0.05), the null hypothesis is rejected. This means that there is a statistically significant difference in the mean points scored before and after the coach change.\n",
    "\n",
    "So, the results suggest that the coach change had a significant effect on the number of points scored by the Cleveland Cavaliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "\n",
    "### Task 4\n",
    "Download [**the similar dataset**](https://drive.google.com/file/d/0Bz9_0VdXvv9bRHhuRTI1aXBQcTA/view?usp=sharing&resourcekey=0-jGIaWyk0bXyECNSzB3x38w) with scores from playoff games in 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>...</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42015</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>41500407</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>CLE @ GSW</td>\n",
       "      <td>W</td>\n",
       "      <td>241</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42015</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>GSW</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>41500407</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>GSW vs. CLE</td>\n",
       "      <td>L</td>\n",
       "      <td>239</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42015</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>GSW</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>41500406</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>GSW @ CLE</td>\n",
       "      <td>L</td>\n",
       "      <td>238</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42015</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>41500406</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>CLE vs. GSW</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42015</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>41500405</td>\n",
       "      <td>2016-06-13</td>\n",
       "      <td>CLE @ GSW</td>\n",
       "      <td>W</td>\n",
       "      <td>241</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON_ID     TEAM_ID TEAM_ABBREVIATION              TEAM_NAME   GAME_ID  \\\n",
       "0      42015  1610612739               CLE    Cleveland Cavaliers  41500407   \n",
       "1      42015  1610612744               GSW  Golden State Warriors  41500407   \n",
       "2      42015  1610612744               GSW  Golden State Warriors  41500406   \n",
       "3      42015  1610612739               CLE    Cleveland Cavaliers  41500406   \n",
       "4      42015  1610612739               CLE    Cleveland Cavaliers  41500405   \n",
       "\n",
       "    GAME_DATE      MATCHUP WL  MIN  PTS  ...  FT_PCT  OREB  DREB  REB  AST  \\\n",
       "0  2016-06-19    CLE @ GSW  W  241   93  ...   0.840     9    39   48   17   \n",
       "1  2016-06-19  GSW vs. CLE  L  239   89  ...   0.769     7    32   39   22   \n",
       "2  2016-06-16    GSW @ CLE  L  238  101  ...   0.690     9    26   35   19   \n",
       "3  2016-06-16  CLE vs. GSW  W  240  115  ...   0.781     8    37   45   24   \n",
       "4  2016-06-13    CLE @ GSW  W  241  112  ...   0.609     8    33   41   15   \n",
       "\n",
       "   STL  BLK  TOV  PF  PLUS_MINUS  \n",
       "0    7    6   11  15         4.0  \n",
       "1    7    5   10  23        -4.0  \n",
       "2    5    3   14  25       -14.0  \n",
       "3   12    7   10  25        14.0  \n",
       "4   11    9   16  22        15.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016 = pd.read_csv('nba_playoff_16.csv', sep=';')\n",
    "df_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "### Task 5\n",
    "Test the hypothesis that **number of blocks (BLK)** are from the same distribution in both the NBA playoffs and in the NBA regular season for 2015/2016 season for the **Toronto Raptors**. \n",
    "\n",
    "- We will be working with two samples with different sizes again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=0.965, p=0.000\n",
      "df_2015 data does not look Gaussian (reject H0)\n",
      "Statistics=0.960, p=0.000\n",
      "df_2016 data does not look Gaussian (reject H0)\n",
      "Statistics=0.007, p=0.933\n",
      "Samples have equal variances (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro, levene\n",
    "\n",
    "# Check for normality in df_2015\n",
    "stat, p = shapiro(df_2015['BLK'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('df_2015 data looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('df_2015 data does not look Gaussian (reject H0)')\n",
    "\n",
    "# Check for normality in df_2016\n",
    "stat, p = shapiro(df_2016['BLK'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('df_2016 data looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('df_2016 data does not look Gaussian (reject H0)')\n",
    "\n",
    "# Check for equal variances\n",
    "stat, p = levene(df_2015['BLK'], df_2016['BLK'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Samples have equal variances (fail to reject H0)')\n",
    "else:\n",
    "    print('Samples do not have equal variances (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test was performed on the 'BLK' column of the df_2015 DataFrame to check if the data is normally distributed. The test statistic is 0.965 and the p-value is 0.000. Since the p-value is less than 0.05, we reject the null hypothesis (H0) that the data is normally distributed. Therefore, the 'BLK' data in df_2015 does not follow a normal distribution.\n",
    "\n",
    "The same test was performed on the 'BLK' column of the df_2016 DataFrame. The test statistic is 0.960 and the p-value is 0.000. Again, since the p-value is less than 0.05, we reject the null hypothesis (H0) that the data is normally distributed. Therefore, the 'BLK' data in df_2016 does not follow a normal distribution either.\n",
    "\n",
    "Levene's test was performed to check if the variances of the 'BLK' data in the df_2015 and df_2016 DataFrames are equal. The test statistic is 0.007 and the p-value is 0.933. Since the p-value is greater than 0.05, we fail to reject the null hypothesis (H0) that the variances are equal. Therefore, the 'BLK' data in df_2015 and df_2016 have equal variances.\n",
    "\n",
    "In summary, both the 'BLK' data in df_2015 and df_2016 are not normally distributed, but they have equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=211177.500, p=0.968\n",
      "Same distribution (fail to reject H0) for BLK\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "stat, p = mannwhitneyu(df_2015['BLK'], df_2016['BLK'])\n",
    "\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0) for BLK')\n",
    "else:\n",
    "    print('Different distribution (reject H0) for BLK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mann-Whitney U test was performed on the 'BLK' column of the df_2015 and df_2016 DataFrames to check if the two independent samples were selected from populations having the same distribution.\n",
    "\n",
    "The test statistic is 211177.500 and the p-value is 0.968. The p-value is greater than the significance level of 0.05, so we fail to reject the null hypothesis (H0).\n",
    "\n",
    "This means that there is not enough evidence to conclude that the distributions of 'BLK' in df_2015 and df_2016 are different. In other words, the 'BLK' data in df_2015 and df_2016 come from populations with the same distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "### Task 6\n",
    "Test the hypothesis that the number of points (PTS) scored by Cleveland Cavaliers is equally distributed for all 3 seasons. \n",
    "\n",
    "- In this case, we need a hypothesis test that compares more than 2 distributions at the same. (You will need to go through the scipy documentation or google to figure out what kind of test is required.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=0.997, p=0.000\n",
      "df_2013 PTS data does not look Gaussian (reject H0)\n",
      "Statistics=0.997, p=0.000\n",
      "df_2014 PTS data does not look Gaussian (reject H0)\n",
      "Statistics=0.998, p=0.001\n",
      "df_2015 PTS data does not look Gaussian (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Check for normality in df_2013\n",
    "stat, p = shapiro(df_2013['PTS'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('df_2013 PTS data looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('df_2013 PTS data does not look Gaussian (reject H0)')\n",
    "\n",
    "# Check for normality in df_2014\n",
    "stat, p = shapiro(df_2014['PTS'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('df_2014 PTS data looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('df_2014 PTS data does not look Gaussian (reject H0)')\n",
    "\n",
    "# Check for normality in df_2015\n",
    "stat, p = shapiro(df_2015['PTS'])\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('df_2015 PTS data looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('df_2015 PTS data does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro-Wilk test was performed on the 'PTS' column of the df_2013 DataFrame to check if the data is normally distributed. The test statistic is 0.997 and the p-value is 0.000. Since the p-value is less than 0.05, we reject the null hypothesis (H0) that the data is normally distributed. Therefore, the 'PTS' data in df_2013 does not follow a normal distribution.\n",
    "\n",
    "The same test was performed on the 'PTS' column of the df_2014 DataFrame. The test statistic is 0.997 and the p-value is 0.000. Again, since the p-value is less than 0.05, we reject the null hypothesis (H0) that the data is normally distributed. Therefore, the 'PTS' data in df_2014 does not follow a normal distribution either.\n",
    "\n",
    "The Shapiro-Wilk test was also performed on the 'PTS' column of the df_2015 DataFrame. The test statistic is 0.998 and the p-value is 0.001. Since the p-value is less than 0.05, we reject the null hypothesis (H0) that the data is normally distributed. Therefore, the 'PTS' data in df_2015 does not follow a normal distribution.\n",
    "\n",
    "In summary, the 'PTS' data in all three DataFrames (df_2013, df_2014, df_2015) are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=62.612, p=0.000\n",
      "Different distribution (reject H0) for PTS\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Perform Kruskal-Wallis H test\n",
    "stat, p = kruskal(df_2013['PTS'], df_2014['PTS'], df_2015['PTS'])\n",
    "\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0) for PTS')\n",
    "else:\n",
    "    print('Different distribution (reject H0) for PTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kruskal-Wallis H test was performed on the 'PTS' column of the df_2013, df_2014, and df_2015 DataFrames to check if the three independent samples were selected from populations having the same distribution.\n",
    "\n",
    "The test statistic is 62.612 and the p-value is 0.000. The p-value is less than the significance level of 0.05, so we reject the null hypothesis (H0).\n",
    "\n",
    "This means that there is enough evidence to conclude that the distributions of 'PTS' in df_2013, df_2014, and df_2015 are different. In other words, the 'PTS' data in df_2013, df_2014, and df_2015 do not come from populations with the same distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow Up\n",
    "**Between which seasons can we see the significant difference?**\n",
    "\n",
    "+ Unfortunatelly, this is not the output of an ANOVA test and further tests are needed to be run.\n",
    "+ Note: Lebron James came back to the Cleveland Caveliers prior to season 2014/2015. We can use this fact to interpret our results correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specify correct column names using `group_col` and `val_col` args",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2013\u001b[39m\u001b[38;5;124m'\u001b[39m: df_2013[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPTS\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2014\u001b[39m\u001b[38;5;124m'\u001b[39m: df_2014[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPTS\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015\u001b[39m\u001b[38;5;124m'\u001b[39m: df_2015[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPTS\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Perform Dunn's test\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m posthoc \u001b[38;5;241m=\u001b[39m posthoc_dunn(a\u001b[38;5;241m=\u001b[39mdata, val_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_column_name\u001b[39m\u001b[38;5;124m'\u001b[39m, group_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_column_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(posthoc)\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\scikit_posthocs\\_posthocs.py:351\u001b[0m, in \u001b[0;36mposthoc_dunn\u001b[1;34m(a, val_col, group_col, p_adjust, sort)\u001b[0m\n\u001b[0;32m    348\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m ss\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39msf(np\u001b[38;5;241m.\u001b[39mabs(z_value))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p_value\n\u001b[1;32m--> 351\u001b[0m x, _val_col, _group_col \u001b[38;5;241m=\u001b[39m __convert_to_df(a, val_col, group_col)\n\u001b[0;32m    352\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[_group_col, _val_col], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    354\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\16476\\anaconda3\\Lib\\site-packages\\scikit_posthocs\\_posthocs.py:71\u001b[0m, in \u001b[0;36m__convert_to_df\u001b[1;34m(a, val_col, group_col, val_id, group_id)\u001b[0m\n\u001b[0;32m     69\u001b[0m     x \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m {group_col, val_col}\u001b[38;5;241m.\u001b[39missubset(a\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpecify correct column names using `group_col` and `val_col` args\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, val_col, group_col\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(a, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m a\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m2\u001b[39m)):\n",
      "\u001b[1;31mValueError\u001b[0m: Specify correct column names using `group_col` and `val_col` args"
     ]
    }
   ],
   "source": [
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "# Create a DataFrame where each group is a separate column\n",
    "data = pd.DataFrame({'2013': df_2013['PTS'], '2014': df_2014['PTS'], '2015': df_2015['PTS']})\n",
    "\n",
    "# Perform Dunn's test\n",
    "posthoc = posthoc_dunn(a=data, val_col='value_column_name', group_col='group_column_name')\n",
    "\n",
    "print(posthoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       2013  2014   2015\n",
      "0       NaN   NaN  144.0\n",
      "1       NaN   NaN   92.0\n",
      "2       NaN   NaN   98.0\n",
      "3       NaN   NaN  101.0\n",
      "4       NaN   NaN  110.0\n",
      "...     ...   ...    ...\n",
      "7375   87.0   NaN    NaN\n",
      "7376  107.0   NaN    NaN\n",
      "7377  116.0   NaN    NaN\n",
      "7378   95.0   NaN    NaN\n",
      "7379   97.0   NaN    NaN\n",
      "\n",
      "[7380 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
